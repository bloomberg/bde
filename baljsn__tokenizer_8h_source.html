<!doctype HTML public "-//W3C//DTD HTML 4.0 Frameset//EN">
<html>
<title>BDE 3.0</title>
<html>
<pre>
// baljsn_tokenizer.h                                                 -*-C++-*-
#ifndef INCLUDED_BALJSN_TOKENIZER
#define INCLUDED_BALJSN_TOKENIZER

#ifndef INCLUDED_BSLS_IDENT
#include &lt;bsls_ident.h&gt;
#endif
BSLS_IDENT(&quot;$Id: $&quot;)

//@PURPOSE: Provide a tokenizer for extracting JSON data from a &#39;streambuf&#39;.
//
//@CLASSES:
//  baljsn::Tokenizer: tokenizer for parsing JSON data from a &#39;streambuf&#39;
//
//@SEE_ALSO: baljsn_decoder, baljsn_parserutil
//
//@DESCRIPTION: This component provides a class, &#39;baljsn::Tokenizer&#39;, that
// traverses data stored in a &#39;bsl::streambuf&#39; one node at a time and provides
// clients access to the data associated with that node, including its type and
// data value.  Client code can use the &#39;reset&#39; function to associate a
// &#39;bsl::streambuf&#39; containing JSON data with a tokenizer object and then call
// the &#39;advanceToNextToken&#39; function to extract individual data values.
//
// This &#39;class&#39; was created to be used by other components in the &#39;baljsn&#39;
// package and in most cases clients should use the &#39;baljsn_decoder&#39; component
// instead of using this &#39;class&#39;.
//
///Usage
///-----
// This section illustrates intended use of this component.
//
///Example 1: Extracting JSON Data into an Object
///----------------------------------------------
// For this example, we will use &#39;baljsn::Tokenizer&#39; to read each node in a
// JSON document and populate a simple &#39;Employee&#39; object.
//
// First, we will define the JSON data that the tokenizer will traverse over:
//..
//  const char *INPUT = &quot;    {\n&quot;
//                      &quot;        \&quot;street\&quot; : \&quot;Lexington Ave\&quot;,\n&quot;
//                      &quot;        \&quot;state\&quot; : \&quot;New York\&quot;,\n&quot;
//                      &quot;        \&quot;zipcode\&quot; : 10022\n&quot;
//                      &quot;    }&quot;;
//..
// Next, we will construct populate a &#39;streambuf&#39; with this data:
//..
//  bdlsb::FixedMemInStreamBuf isb(INPUT, bsl::strlen(INPUT));
//..
// Then, we will create a &#39;baljsn::Tokenizer&#39; object and associate the above
// streambuf with it:
//..
//  baljsn::Tokenizer tokenizer;
//  tokenizer.reset(&amp;isb);
//..
// Next, we will create an address record type and object.
//..
//  struct Address {
//      bsl::string d_street;
//      bsl::string d_state;
//      int         d_zipcode;
//  } address = { &quot;&quot;, &quot;&quot;, 0 };
//..
// Then, we will traverse the JSON data one node at a time:
//..
//  // Read &#39;{&#39;
//
//  int rc = tokenizer.advanceToNextToken();
//  assert(!rc);
//
//  baljsn::Tokenizer::TokenType token = tokenizer.tokenType();
//  assert(baljsn::Tokenizer::e_START_OBJECT == token);
//
//  rc = tokenizer.advanceToNextToken();
//  assert(!rc);
//  token = tokenizer.tokenType();
//
//  // Continue reading elements till &#39;}&#39; is encountered
//
//  while (baljsn::Tokenizer::e_END_OBJECT != token) {
//      assert(baljsn::Tokenizer::e_ELEMENT_NAME == token);
//
//      // Read element name
//
//      bslstl::StringRef nodeValue;
//      rc = tokenizer.value(&amp;nodeValue);
//      assert(!rc);
//
//      bsl::string elementName = nodeValue;
//
//      // Read element value
//
//      int rc = tokenizer.advanceToNextToken();
//      assert(!rc);
//
//      token = tokenizer.tokenType();
//      assert(baljsn::Tokenizer::e_ELEMENT_VALUE == token);
//
//      rc = tokenizer.value(&amp;nodeValue);
//      assert(!rc);
//
//      // Extract the simple type with the data
//
//      if (elementName == &quot;street&quot;) {
//          rc = baljsn::ParserUtil::getValue(&amp;address.d_street, nodeValue);
//          assert(!rc);
//      }
//      else if (elementName == &quot;state&quot;) {
//          rc = baljsn::ParserUtil::getValue(&amp;address.d_state, nodeValue);
//          assert(!rc);
//      }
//      else if (elementName == &quot;zipcode&quot;) {
//          rc = baljsn::ParserUtil::getValue(&amp;address.d_zipcode, nodeValue);
//          assert(!rc);
//      }
//
//      rc = tokenizer.advanceToNextToken();
//      assert(!rc);
//      token = tokenizer.tokenType();
//  }
//..
// Finally, we will verify that the &#39;address&#39; aggregate has the correct values:
//..
//  assert(&quot;Lexington Ave&quot; == address.d_street);
//  assert(&quot;New York&quot;      == address.d_state);
//  assert(10022           == address.d_zipcode);
//..

#ifndef INCLUDED_BALSCM_VERSION
#include &lt;balscm_version.h&gt;
#endif

#ifndef INCLUDED_BDLMA_BUFFEREDSEQUENTIALALLOCATOR
#include &lt;bdlma_bufferedsequentialallocator.h&gt;
#endif

#ifndef INCLUDED_BSLS_ALIGNEDBUFFER
#include &lt;bsls_alignedbuffer.h&gt;
#endif

#ifndef INCLUDED_BSLS_TYPES
#include &lt;bsls_types.h&gt;
#endif

#ifndef INCLUDED_BSL_STRING
#include &lt;bsl_string.h&gt;
#endif

#ifndef INCLUDED_BSL_STREAMBUF
#include &lt;bsl_streambuf.h&gt;
#endif

namespace BloombergLP {
namespace baljsn {

                              // ===============
                              // class Tokenizer
                              // ===============

class Tokenizer {
    // This &#39;class&#39; provides a mechanism for traversing JSON data stored in a
    // &#39;bsl::streambuf&#39; one node at a time and allows clients to access the
    // data associated with that node, including its type and data value.

  public:
    // TYPES
    enum TokenType {
        // This &#39;enum&#39; lists all the possible token types.

        e_BEGIN = 1,                  // starting token
        e_ELEMENT_NAME,               // element name
        e_START_OBJECT,               // start of an object (&#39;{&#39;)
        e_END_OBJECT,                 // end of an object   (&#39;}&#39;)
        e_START_ARRAY,                // start of an array  (&#39;[&#39;)
        e_END_ARRAY,                  // end of an array    (&#39;]&#39;)
        e_ELEMENT_VALUE,              // element value of a simple type
        e_ERROR                       // error token
    };

  private:
    // TYPES
    enum ContextType {
        // This &#39;enum&#39; lists the possible contexts that the tokenizer can be
        // in.

        e_OBJECT_CONTEXT = 1,         // object context
        e_ARRAY_CONTEXT               // array context
    };

    // Intermediate data buffer used for reading data from the stream.

    enum {
        k_BUFSIZE = 1024 * 8,
        k_MAX_STRING_SIZE = k_BUFSIZE - 1
    };

    // DATA
    bsls::AlignedBuffer&lt;k_BUFSIZE&gt;  d_buffer;               // buffer

    bdlma::BufferedSequentialAllocator    d_allocator;           // allocator
                                                                 // (owned)

    bsl::string                          d_stringBuffer;         // string
                                                                 // buffer

    bsl::streambuf                      *d_streambuf_p;          // streambuf
                                                                 // (held, not
                                                                 // owned)

    bsl::size_t                          d_cursor;               // current
                                                                 // cursor

    bsl::size_t                          d_valueBegin;           // cursor for
                                                                 // beginning
                                                                 // of value

    bsl::size_t                          d_valueEnd;             // cursor for
                                                                 // end of
                                                                 // value

    bsl::size_t                          d_valueIter;            // cursor for
                                                                 // iterating
                                                                 // value

    TokenType                            d_tokenType;            // token type

    ContextType                          d_context;              // context
                                                                 // type

    bool                                 d_allowStandAloneValues;// option for
                                                                 // allowing
                                                                 // stand alone
                                                                 // values

    // PRIVATE MANIPULATORS
    int extractStringValue();
        // Extract the string value starting at the current data cursor and
        // update the value begin and end pointers to refer to the begin and
        // end of the extracted string.  Return 0 on success and a non-zero
        // value otherwise.

    int moveValueCharsToStartAndReloadBuffer();
        // Move the current sequence of characters being tokenized to the front
        // of the internal string buffer, &#39;d_stringBuffer&#39;, and then append
        // additional characters, from the internally-held &#39;streambuf&#39;
        // (&#39;d_streambuf_p&#39;) to the end of that sequence up to a maximum
        // sequence length of &#39;d_buffer.size()&#39; characters.  Return the number
        // of bytes read from the &#39;streambuf&#39;.

    int reloadStringBuffer();
        // Reload the string buffer with new data read from the underlying
        // &#39;streambuf&#39; and overwriting the current buffer.  After reading
        // update the cursor to the new read location.  Return the number of
        // bytes read from the &#39;streambuf&#39;.

    int expandBufferForLargeValue();
        // Increase the size of the string buffer, &#39;d_stringBuffer&#39;, and then
        // append additional characters, from the internally-held &#39;streambuf&#39; (
        // &#39;d_streambuf_p&#39;) to the end of the current sequence of characters.
        // Return 0 on success and a non-zero value otherwise.

    int skipWhitespace();
        // Skip all whitespace characters and position the cursor onto the
        // first non-whitespace character.  Return 0 on success and a non-zero
        // value otherwise.

    int skipNonWhitespaceOrTillToken();
        // Skip all characters until a whitespace or a token character is
        // encountered and position the cursor onto the first such character.
        // Return 0 on success and a non-zero value otherwise.

    // Not implemented:
    Tokenizer(const Tokenizer&amp;);

  public:
    // CREATORS
    explicit Tokenizer(bslma::Allocator *basicAllocator = 0);
        // Create a &#39;Reader&#39; object.  Optionally specify a &#39;basicAllocator&#39;
        // used to supply memory.  If &#39;basicAllocator&#39; is 0, the currently
        // installed default allocator is used.

    ~Tokenizer();
        // Destroy this object.

    // MANIPULATORS
    void reset(bsl::streambuf *streambuf);
        // Reset this tokenizer to read data from the specified &#39;streambuf&#39;.
        // Note that the reader will not be on a valid node until
        // &#39;advanceToNextToken&#39; is called.  Note that this function does not
        // change the value of the &#39;allowStandAloneValues&#39; option.

    int advanceToNextToken();
        // Move to the next token in the data steam.  Return 0 on success and a
        // non-zero value otherwise.  Note that each call to
        // &#39;advanceToNextToken&#39; invalidates the string references returned by
        // the &#39;value&#39; accessor for prior nodes.

    int resetStreamBufGetPointer();
        // Reset the get pointer of the &#39;streambuf&#39; held by this object to
        // refer to the byte following the last processed byte, if the held
        // &#39;streambuf&#39; supports seeking, and return an error otherwise leaving
        // this object unchanged.  After a successful function return users can
        // read data from the &#39;streambuf&#39; where this object stopped.  Return 0
        // on success, and a non-zero value otherwise.

    void setAllowStandAloneValues(bool value);
        // Set the &#39;allowStandAloneValues&#39; option to the specified &#39;value&#39;.  If
        // the &#39;allowStandAloneValues&#39; value is &#39;true&#39; this tokenizer will
        // successfully tokenize JSON values (strings and numbers).  If the
        // option&#39;s value is &#39;false&#39; then the tokenizer will only tokenize
        // complete JSON documents (JSON objects and arrays) and return an
        // error for stand alone JSON values.  By default, the value of the
        // &#39;allowStandAloneValues&#39; is &#39;true&#39;.

    // ACCESSORS
    TokenType tokenType() const;
        // Return the token type of the current token.

    bool allowStandAloneValues() const;
        // Return the value of the &#39;allowStandAloneValues&#39; option of this
        // tokenizer.

    int value(bslstl::StringRef *data) const;
        // Load into the specified &#39;data&#39; the value of the specified token if
        // the current token&#39;s type is &#39;BAEJSN_ELEMENT_NAME&#39; or
        // &#39;BAEJSN_ELEMENT_VALUE&#39; or leave &#39;data&#39; unmodified otherwise.  Return
        // 0 on success and a non-zero value otherwise.
};

// ============================================================================
//                            INLINE DEFINITIONS
// ============================================================================

// CREATORS
inline
Tokenizer::Tokenizer(bslma::Allocator *basicAllocator)
: d_allocator(d_buffer.buffer(), k_BUFSIZE, basicAllocator)
, d_stringBuffer(&amp;d_allocator)
, d_streambuf_p(0)
, d_cursor(0)
, d_valueBegin(0)
, d_valueEnd(0)
, d_valueIter(0)
, d_tokenType(e_BEGIN)
, d_context(e_OBJECT_CONTEXT)
, d_allowStandAloneValues(true)
{
    d_stringBuffer.reserve(k_MAX_STRING_SIZE);
}

inline
Tokenizer::~Tokenizer()
{
}

// MANIPULATORS
inline
void Tokenizer::reset(bsl::streambuf *streambuf)
{
    d_streambuf_p = streambuf;
    d_stringBuffer.clear();
    d_cursor      = 0;
    d_valueBegin  = 0;
    d_valueEnd    = 0;
    d_valueIter   = 0;
    d_tokenType   = e_BEGIN;
}

inline
void Tokenizer::setAllowStandAloneValues(bool value)
{
    d_allowStandAloneValues = value;
}

// ACCESSORS
inline
Tokenizer::TokenType Tokenizer::tokenType() const
{
    return d_tokenType;
}

inline
bool Tokenizer::allowStandAloneValues() const
{
    return d_allowStandAloneValues;
}
}  // close package namespace

}  // close enterprise namespace

#endif

// ----------------------------------------------------------------------------
// Copyright 2015 Bloomberg Finance L.P.
//
// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
// ----------------------------- END-OF-FILE ----------------------------------
</pre>
</body>
</html>
