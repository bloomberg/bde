<!doctype HTML public "-//W3C//DTD HTML 4.0 Frameset//EN">
<html>
<title>BDE 3.0</title>
<html>
<pre>
// bdlmt_threadmultiplexor.h                                          -*-C++-*-

// ----------------------------------------------------------------------------
//                                   NOTICE
//
// This component is not up to date with current BDE coding standards, and
// should not be used as an example for new development.
// ----------------------------------------------------------------------------

#ifndef INCLUDED_BDLMT_THREADMULTIPLEXOR
#define INCLUDED_BDLMT_THREADMULTIPLEXOR

#ifndef INCLUDED_BSLS_IDENT
#include &lt;bsls_ident.h&gt;
#endif
BSLS_IDENT(&quot;$Id: $&quot;)

//@PURPOSE: Provide a mechanism for partitioning a collection of threads.
//
//@CLASSES:
// bdlmt::ThreadMultiplexor: mechanism to partition multi-threaded processing
//
//@SEE_ALSO: bdlmt_threadpool, bdlmt_fixedthreadpool
//
//@DESCRIPTION: This component provides a mechanism for partitioning a
// collection of threads, so that a single collection of threads (e.g., a
// thread pool) can be used to process various types of user-defined functions
// (&quot;jobs&quot;) while sharing the thread resources equitably between them.  A
// typical example where this type of partitioning is desired is an application
// that performs both I/O and CPU-intensive processing.  The traditional
// approach is to create two thread pools--one for I/O, and one for
// processing--and pass control (in the form of a callback) from one thread
// pool to the other.  However, there are several problems with this approach.
// Firstly, the process incurs the overhead of context switching between
// threads, which must necessarily occur because there are two different thread
// pools.  Secondly, the process may not be able to adapt well to imbalances
// between one type of processing versus the other if the number of threads in
// each thread pool is bounded.  In this case, a large number of jobs may be
// enqueued while some portion of threads allocated to the process go unused.
// On the other hand, simply sharing a single thread pool without a provision
// for partitioning the use of threads may result in one type of processing
// starving the other.
//
// The &#39;bdlmt::ThreadMultiplexor&#39; provides an API, &#39;processJob&#39;, to process
// user-specified jobs.  A multiplexor instance is configured with a maximum
// number of &quot;processors&quot;, i.e., the maximum number of threads that may process
// jobs at any particular time.  Additional threads enqueue jobs to a pending
// job queue, which is processed by the next available processing thread.
//
// Typically, a &#39;bdlmt::ThreadMultiplexor&#39; instance is used in conjunction with
// a thread pool (e.g., &#39;bdlmt::FixedThreadPool&#39;), where each thread pool
// thread calls the multiplexor &#39;processJob&#39; method to perform some work.  The
// multiplexor guarantees that no more that the configured number of threads
// will process jobs concurrently.  This guarantee allows a single thread pool
// to be used in a variety of situations that require partitioning thread
// resources.
//
///Thread Safety
///-------------
// The &#39;bdlmt::ThreadMultiplexor&#39; class is both *fully thread-safe* (i.e., all
// non-creator methods can correctly execute concurrently), and is
// *thread-enabled* (i.e., the class does not function correctly in a
// non-multi-threading environment).  See &#39;bsldoc_glossary&#39; for complete
// definitions of *fully thread-safe* and *thread-enabled*.
//
///Usage
///-----
// This section illustrates intended use of this component.
//
///Example 1: Multiple Work Queues
///- - - - - - - - - - - - - - - -
// The following usage example illustrates how the &#39;bdlmt::ThreadMultiplexor&#39;
// can be used to share thread resources between three separate work queues.
// Assume that there are three classes of jobs: jobs that are important, jobs
// that are urgent, and jobs that are critical.  We would like to execute each
// class of jobs in a single thread pool, but we want ensure that all types of
// jobs can be executed at any time.
//
// We begin by defining a class that encapsulates the notion of a job queue.
// Our &#39;JobQueue&#39; class holds a reference to a &#39;bdlmt::FixedThreadPool&#39;, used
// to instantiate the job queue, and owns an instance of
// &#39;bdlmt::ThreadMultiplexor&#39;, used to process jobs.
//..
//  class JobQueue {
//      // This class defines a generic processor for user-defined functions
//      // (&quot;jobs&quot;).  Jobs specified to the &#39;processJob&#39; method are executed
//      // in the thread pool specified at construction.
//
//    public:
//      // PUBLIC TYPES
//      typedef bdlmt::ThreadMultiplexor::Job Job;
//          // A callback of this type my be specified to the &#39;processJob&#39;
//          // method.
//
//    private:
//      // DATA
//      bdlmt::FixedThreadPool   *d_threadPool_p;  // (held, not owned)
//      bdlmt::ThreadMultiplexor  d_multiplexor;   // used to partition threads
//
//    private:
//      // NOT IMPLEMENTED
//      JobQueue(const JobQueue&amp;);
//      JobQueue&amp; operator=(const JobQueue&amp;);
//
//    public:
//      // CREATORS
//      JobQueue(int                     maxProcessors,
//               bdlmt::FixedThreadPool *threadPool,
//               bslma::Allocator       *basicAllocator = 0);
//        // Create a job queue that executes jobs in the specified
//        // &#39;threadPool&#39; using no more than the specified &#39;maxProcessors&#39;.
//        // Optionally specify a &#39;basicAllocator&#39; used to supply memory.  If
//        // &#39;basicAllocator is 0, the currently installed default allocator
//        // is used.
//
//      ~JobQueue();
//          // Destroy this object.
//
//      // MANIPULATORS
//      int processJob(const Job&amp; job);
//          // Process the specified &#39;job&#39; in the thread pool specified at
//          // construction.  Return 0 on success, and a non-zero value
//          // otherwise.
//  };
//..
// The maximum number of processors for the multiplexor instance owned by each
// &#39;JobQueue&#39; is configured using the following formula, for
// T = number of threads and M = number of multiplexors &gt; 1:
//..
//   maxProc = ceil(T / (M-1))-1
//..
// This allows multiple &#39;JobQueue&#39; instances to share the same threadpool
// without starving each other when the thread pool has more than one thread.
// For this usage example, we assume M (number of multiplexors) = 3, and T
// (number of threads) = 5, so maxProc = 2.  It is important to note that every
// call to &#39;processJob&#39; enqueues a job to the thread pool, so the length of the
// thread pool queue determines the maximum number of jobs that can be accepted
// by the JobQueue.  (Multiple JobQueues share the same maximum *together*, so
// not all will be able to reach their individual maximum at the same time).
//..
//
//   JobQueue::JobQueue(int                     maxProcessors,
//                      bdlmt::FixedThreadPool *threadPool,
//                      bslma::Allocator       *basicAllocator)
//   : d_threadPool_p(threadPool)
//   , d_multiplexor (maxProcessors,
//                    threadPool-&gt;queueCapacity(),
//                    basicAllocator)
//  {
//  }
//
//  JobQueue::~JobQueue()
//  {
//  }
//..
// The &#39;processJob&#39; method enqueues a secondary callback into the thread pool
// that executes the user-specified &#39;job&#39; through the multiplexor.
//..
//  int JobQueue::processJob(const JobQueue::Job&amp; job)
//  {
//      return d_threadPool_p-&gt;tryEnqueueJob(bdlf::BindUtil::bind(
//                                  &amp;bdlmt::ThreadMultiplexor::processJob&lt;Job&gt;,
//                                  &amp;d_multiplexor,
//                                  job));
//  }
//..
// The following program uses three instances of &#39;JobQueue&#39; to process
// important, urgent, and critical jobs using a single collection of threads.
//..
//  int main(void)
//  {
//      enum {
//          NUM_THREADS   = 5,   // total number of threads
//          NUM_QUEUES    = 3,   // total number of JobQueue objects
//          MAX_QUEUESIZE = 20   // total number of pending jobs
//      };
//
//      int maxProc = bsl::max(1,
//                             ceil(double(MAX_THREADS) / (NUM_QUEUES-1))-1);
//
//      bdlmt::FixedThreadPool tp(NUM_THREADS, MAX_QUEUESIZE);
//      JobQueue             importantQueue(maxProc, &amp;tp);
//      JobQueue             urgentQueue(maxProc, &amp;tp);
//      JobQueue             criticalQueue(maxProc, &amp;tp);
//
//      if (0 != tp.start()) {
//         ASSERT(!&quot;Could not start thread pool!&quot;);
//         return -1;
//      }
//
//      JobQueue::Job ijob =
//         bdlf::BindUtil::bind(&amp;bsls::AtomicInt::add, &amp;iCheck, 1);
//
//      JobQueue::Job ujob = bdlf::BindUtil::bind(
//         bdlf::BindUtil::bind(&amp;bsls::AtomicInt::add, &amp;uCheck, 1);
//
//      JobQueue::Job cjob = bdlf::BindUtil::bind(
//         bdlf::BindUtil::bind(&amp;bsls::AtomicInt::add, &amp;cCheck, 1);
//
//      importantQueue.processJob(ijob);
//      importantQueue.processJob(ijob);
//      importantQueue.processJob(ijob);
//      importantQueue.processJob(ijob);
//      importantQueue.processJob(ijob);
//      importantQueue.processJob(ijob);
//
//      urgentQueue.processJob(ujob);
//      urgentQueue.processJob(ujob);
//      urgentQueue.processJob(ujob);
//      urgentQueue.processJob(ujob);
//
//      criticalQueue.processJob(cjob);
//      criticalQueue.processJob(cjob);
//
//      tp.stop();
//      ASSERT(6 == iCheck);
//      ASSERT(4 == uCheck);
//      ASSERT(2 == cCheck);
//      return 0;
//  }
//..

#ifndef INCLUDED_BDLSCM_VERSION
#include &lt;bdlscm_version.h&gt;
#endif

#ifndef INCLUDED_BDLCC_FIXEDQUEUE
#include &lt;bdlcc_fixedqueue.h&gt;
#endif

#ifndef INCLUDED_BSLS_ATOMIC
#include &lt;bsls_atomic.h&gt;
#endif

#ifndef INCLUDED_BSLALG_TYPETRAITS
#include &lt;bslalg_typetraits.h&gt;
#endif

#ifndef INCLUDED_BSLMA_ALLOCATOR
#include &lt;bslma_allocator.h&gt;
#endif

#ifndef INCLUDED_BSL_FUNCTIONAL
#include &lt;bsl_functional.h&gt;
#endif

namespace BloombergLP {

namespace bdlmt {
                          // =======================
                          // class ThreadMultiplexor
                          // =======================

class ThreadMultiplexor {
    // This class provides a mechanism for facilitating the use of multiple
    // threads to perform various user-defined functions (&quot;jobs&quot;) when some
    // degree of collaboration between threads is required.  The thread
    // multiplexor is configured with a total number of &quot;processors&quot;,
    // representing the number of threads that may process jobs at any
    // particular time.  Additional threads enqueue jobs to a pending job
    // queue, which is processed by the next available processing thread.

  public:
    // PUBLIC TYPES
    typedef bsl::function&lt;void()&gt; Job;
        // A callback of this type may be passed to the &#39;processJob&#39; method.

  private:
    // DATA
    bslma::Allocator     *d_allocator_p;      // memory allocator (held)
    bdlcc::FixedQueue&lt;Job&gt; *d_jobQueue_p;       // pending job queue (owned)
    bsls::AtomicInt        d_numProcessors;    // current number of processors
    int                   d_maxProcessors;    // maximum number of processors

  private:
    // PRIVATE MANIPULATORS
    int processJobQueue();
        // Process the pending job queue.  Execute each functor obtained from
        // the queue in the calling thread if the current number of processors
        // is less than the maximum number of processors.  Otherwise, enqueue
        // the job back to the pending queue.  Return 0 on success, and a
        // non-zero value otherwise.

    // NOT IMPLEMENTED
    ThreadMultiplexor(const ThreadMultiplexor&amp;);
    ThreadMultiplexor&amp; operator=(const ThreadMultiplexor&amp;);

  public:
    // TRAITS
    BSLALG_DECLARE_NESTED_TRAITS(ThreadMultiplexor,
                                 bslalg::TypeTraitUsesBslmaAllocator);

    // CREATORS
    ThreadMultiplexor(int               maxProcessors,
                      int               maxQueueSize,
                      bslma::Allocator *basicAllocator = 0);
        // Create a thread multiplexor which uses, at most, the specified
        // &#39;maxProcessors&#39; number of threads to process user-specified jobs,
        // identified as callbacks of type &#39;Job&#39;.  Jobs that cannot be
        // processed immediately are placed on a queue having the specified
        // &#39;maxQueueSize&#39; to be processed by the next free thread.  Optionally
        // specify a &#39;basicAllocator&#39; used to supply memory.  If
        // &#39;basicAllocator&#39; is 0, the currently installed default allocator is
        // used.  The behavior is undefined unless &#39;0 &lt; maxProcessors&#39; and
        // &#39;0 &lt; maxQueueSize&#39;.

    ~ThreadMultiplexor();
        // Destroy this thread multiplexor object.

    // MANIPULATORS
    template &lt;class JOBTYPE&gt;
    int processJob(const JOBTYPE&amp; job);
        // Process the specified &#39;job&#39; functor in the calling thread if the
        // current number of processors is less than the maximum number of
        // processors.  Otherwise, enqueue &#39;job&#39; to the pending job queue.
        // Return 0 on success, and a non-zero value otherwise.  Note that the
        // only requirements on &#39;JOBTYPE&#39; are that it defines &#39;operator()&#39;,
        // having a &#39;void&#39; return type, and that it defines a copy constructor.

    // ACCESSORS
    int maxProcessors() const;
        // Return the maximum number of active processors.

    int numProcessors() const;
        // Return the current number of active processors.
};

// ============================================================================
//                            INLINE DEFINITIONS
// ============================================================================

// MANIPULATORS
template &lt;class JOBTYPE&gt;
inline
int ThreadMultiplexor::processJob(const JOBTYPE&amp; job)
{
    // Execute &#39;job&#39; in the calling thread if the current number of processors
    // is less than the maximum number of processors.  Otherwise, enqueue &#39;job&#39;
    // to the pending job queue.  In all cases, check the pending job queue at
    // the end of the loop, as the number of processors may have changed,
    // allowing the execution of a job in the current thread.

    int previousNumProcessors = d_numProcessors;
    if (previousNumProcessors &lt; d_maxProcessors &amp;&amp;
        previousNumProcessors ==
                      d_numProcessors.testAndSwap(previousNumProcessors,
                                                  previousNumProcessors + 1)) {
        // Process the job
        job();
        --d_numProcessors;
    }
    else {
        int rc = d_jobQueue_p-&gt;tryPushBack(job);
        if (0 != rc) {
            return rc;                                                // RETURN
        }
    }

    return processJobQueue();
}

// ACCESSORS
inline
int ThreadMultiplexor::maxProcessors() const
{
    return d_maxProcessors;
}

inline
int ThreadMultiplexor::numProcessors() const
{
    return d_numProcessors;
}

}  // close package namespace
}  // close enterprise namespace
#endif

// ----------------------------------------------------------------------------
// Copyright 2015 Bloomberg Finance L.P.
//
// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
// ----------------------------- END-OF-FILE ----------------------------------
</pre>
</body>
</html>
