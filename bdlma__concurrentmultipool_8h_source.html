<!doctype HTML public "-//W3C//DTD HTML 4.0 Frameset//EN">
<html>
<title>BDE 3.0</title>
<html>
<pre>
// bdlma_concurrentmultipool.h                                        -*-C++-*-

// ----------------------------------------------------------------------------
//                                   NOTICE
//
// This component is not up to date with current BDE coding standards, and
// should not be used as an example for new development.
// ----------------------------------------------------------------------------

#ifndef INCLUDED_BDLMA_CONCURRENTMULTIPOOL
#define INCLUDED_BDLMA_CONCURRENTMULTIPOOL

#ifndef INCLUDED_BSLS_IDENT
#include &lt;bsls_ident.h&gt;
#endif
BSLS_IDENT(&quot;$Id: $&quot;)

//@PURPOSE: Provide a memory manager to manage pools of varying block sizes.
//
//@CLASSES:
//   bdlma::ConcurrentMultipool: memory manager that manages pools of blocks
//
//@SEE_ALSO: bdlma_concurrentpool, bdlmca_multipoolallocator
//
//@DESCRIPTION: This component implements a memory manager,
// &#39;bdlma::ConcurrentMultipool&#39;, that maintains a configurable number of
// &#39;bdlma::ConcurrentPool&#39; objects, each dispensing memory blocks of a unique
// size.  The &#39;bdlma::ConcurrentPool&#39; objects are placed in an array, starting
// at index 0, with each successive pool managing memory blocks of a size twice
// that of the previous pool.  Each multipool allocation (deallocation) request
// allocates memory from (returns memory to) the internal pool managing memory
// blocks of the smallest size not less than the requested size, or else from a
// separately managed list of memory blocks, if no internal pool managing
// memory block of sufficient size exists.  Both the &#39;release&#39; method and the
// destructor of a &#39;bdlma::ConcurrentMultipool&#39; release all memory currently
// allocated via the object.
//
// A &#39;bdlma::ConcurrentMultipool&#39; can be depicted visually:
//..
//                    +-----+--- memory blocks of 8 bytes
//                    |     |
//   ========       ----- ----- ------------
//  |8 bytes |----&gt;|     |     |     ...    |
//  &gt;========&lt;      =====^=====^============
//  |16 bytes|
//  &gt;========&lt;      \___________ __________/
//  |32 bytes|                  V
//  &gt;========&lt;              a &quot;chunk&quot;
//  |        |
//  |  ...   |
//  |        |
//   ========
//      |
//      +------- array of &#39;bdlma::ConcurrentPool&#39;
//..
// Note that a &quot;chunk&quot; is a large, contiguous block of memory, internal to a
// &#39;bdlma::ConcurrentPool&#39; maintained by the multipool, from which memory
// blocks of uniform size are dispensed to users.
//
///Thread Safety
///-------------
// &#39;bdlma::ConcurrentMultipool&#39; is *fully thread-safe*, meaning any operation
// on the same object can be safely invoked from any thread.
//
///Configuration at Construction
///-----------------------------
// When creating a &#39;bdlma::ConcurrentMultipool&#39;, clients can optionally
// configure:
//
//: 1 NUMBER OF POOLS -- the number of internal pools (the block size managed
//:   by the first pool is eight bytes, with each successive pool managing
//:   block of a size twice that of the previous pool).
//:
//: 2 GROWTH STRATEGY -- geometrically growing chunk size starting from 1 (in
//:   terms of the number of memory blocks per chunk), or fixed chunk size,
//:   specified as either:
//:   o the unique growth strategy for all pools, or
//:   o (if the number of pools is specified) an array of growth strategies
//:     corresponding to each individual pool
//:   If the growth strategy is not specified, geometric growth is used for all
//:   pools.
//:
//: 3 MAX BLOCKS PER CHUNK -- the maximum number of memory blocks within a
//:   chunk, specified as either:
//:     o the unique maximum-blocks-per-chunk value for all of the pools, or
//:     o an array of maximum-blocks-per-chunk values corresponding to each
//:       individual pool.
//:   If the maximum blocks per chunk is not specified, an
//:   implementation-defined default value is used.  Note that the maximum
//:   blocks per chunk can be configured only if the number of pools is also
//:   configured.
//:
//: 4 BASIC ALLOCATOR -- the allocator used to supply memory (to replenish an
//:   internal pool, or directly if the maximum block size is exceeded).  If
//:   not specified, the currently installed default allocator (see
//:   &#39;bslma_default&#39;) is used.
//
// A default-constructed multipool has a relatively small,
// implementation-defined number of pools &#39;N&#39; with respective block sizes
// ranging from &#39;2^3 = 8&#39; to &#39;2^(N+2)&#39;.  By default, the initial chunk size,
// (i.e., the number of blocks of a given size allocated at once to replenish a
// pool&#39;s memory) is 1, and each pool&#39;s chunk size grows geometrically until it
// reaches an implementation-defined maximum, at which it is capped.  Finally,
// unless otherwise specified, all memory comes from the allocator that was the
// currently installed default allocator at the time the
// &#39;bdlma::ConcurrentMultipool&#39; was created.
//
// Using the various pooling options described above, we can configure the
// number of pools maintained, whether replenishment should be adaptive (i.e.,
// geometric starting with 1) or fixed at a maximum chunk size, what that
// maximum chunk size should be (which need not be an integral power of 2), and
// the underlying allocator used to supply memory.  Note that both GROWTH
// STRATEGY and MAX BLOCKS PER CHUNK can be specified separately either as a
// single value applying to all of the maintained pools, or as an array of
// values, with the elements applying to each individually maintained pool.
//
//
///Usage
///-----
// This section illustrates intended use of this component.
//
///Example 1: Using a &#39;bdlma::ConcurrentMultipool&#39; Directly
/// - - - - - - - - - - - - - - - - - - - - - - - - - - - -
// A &#39;bdlma::ConcurrentMultipool&#39; can be used by containers that hold different
// types of elements, each of uniform size, for efficient memory allocation of
// new elements.  Suppose we have a factory class, &#39;my_MessageFactory&#39;, that
// creates messages based on user requests.  Each message is created with the
// most efficient memory storage possible - using predefined 8-byte, 16-byte
// and 32-byte buffers.  If the message size exceeds the three predefined
// values, a generic message is used.  For efficient memory allocation of
// messages, we use a &#39;bdlma::ConcurrentMultipool&#39;.
//
// First, we define our message types as follows:
//..
//  class my_MessageFactory;
//
//  class my_Message {
//      // This class represents a general message interface that provides a
//      // &#39;getMessage&#39; method for clients to retrieve the underlying message.
//
//    public:
//      // ACCESSORS
//      virtual const char *getMessage() = 0;
//          // Return the null-terminated message string.
//  };
//
//  class my_SmallMessage : public my_Message {
//      // This class represents an 8-byte message (including null terminator).
//
//      // DATA
//      char d_buffer[8];
//
//      // FRIEND
//      friend class my_MessageFactory;
//
//      // NOT IMPLEMENTED
//      my_SmallMessage(const my_SmallMessage&amp;);
//      my_SmallMessage&amp; operator=(const my_SmallMessage&amp;);
//
//      // PRIVATE CREATORS
//      my_SmallMessage(const char *msg, int length)
//      {
//          assert(length &lt;= 7);
//
//          bsl::memcpy(d_buffer, msg, length);
//          d_buffer[length] = &#39;\0&#39;;
//      }
//
//      // PRIVATE ACCESSORS
//      virtual const char *getMessage()
//      {
//          return d_buffer;
//      }
//  };
//
//  class my_MediumMessage : public my_Message {
//      // This class represents a 16-byte message (including null
//      // terminator).
//
//      // DATA
//      char d_buffer[16];
//
//      // FRIEND
//      friend class my_MessageFactory;
//
//      // NOT IMPLEMENTED
//      my_MediumMessage(const my_MediumMessage&amp;);
//      my_MediumMessage&amp; operator=(const my_MediumMessage&amp;);
//
//      // PRIVATE CREATORS
//      my_MediumMessage(const char *msg, int length)
//      {
//          assert(length &lt;= 15);
//
//          bsl::memcpy(d_buffer, msg, length);
//          d_buffer[length] = &#39;\0&#39;;
//      }
//
//      // PRIVATE ACCESSORS
//      virtual const char *getMessage()
//      {
//          return d_buffer;
//      }
//  };
//
//  class my_LargeMessage : public my_Message {
//      // This class represents a 32-byte message (including null
//      // terminator).
//
//      // DATA
//      char d_buffer[32];
//
//      // FRIEND
//      friend class my_MessageFactory;
//
//      // NOT IMPLEMENTED
//      my_LargeMessage(const my_LargeMessage&amp;);
//      my_LargeMessage&amp; operator=(const my_LargeMessage&amp;);
//
//      // PRIVATE CREATORS
//      my_LargeMessage(const char *msg, int length)
//      {
//          assert(length &lt;= 31);
//
//          bsl::memcpy(d_buffer, msg, length);
//          d_buffer[length] = &#39;\0&#39;;
//      }
//
//      // PRIVATE ACCESSORS
//      virtual const char *getMessage()
//      {
//          return d_buffer;
//      }
//  };
//
//  class my_GenericMessage : public my_Message {
//      // This class represents a generic message.
//
//      // DATA
//      char *d_buffer;
//
//      // FRIEND
//      friend class my_MessageFactory;
//
//      // NOT IMPLEMENTED
//      my_GenericMessage(const my_GenericMessage&amp;);
//      my_GenericMessage&amp; operator=(const my_GenericMessage&amp;);
//
//      // PRIVATE CREATORS
//      my_GenericMessage(char *msg) : d_buffer(msg)
//      {
//      }
//
//      // PRIVATE ACCESSORS
//      virtual const char *getMessage()
//      {
//          return d_buffer;
//      }
//  };
//..
// Then we define our factory class, &#39;my_MessageFactory&#39;, as follows:
//..
//  class my_MessageFactory {
//      // This class implements an efficient message factory that builds and
//      // returns messages.  The life-time of the messages created by this
//      // factory is the same as this factory.
//
//      // DATA
//      bdlma::ConcurrentMultipool d_multipool;  // multipool used to supply
//                                               // memory
//
//    private:
//      // Not implemented:
//      my_MessageFactory(const my_MessageFactory&amp;);
//
//    public:
//      // CREATORS
//      my_MessageFactory(bslma::Allocator *basicAllocator = 0);
//          // Create a message factory.  Optionally specify a &#39;basicAllocator&#39;
//          // used to supply memory.  If &#39;basicAllocator&#39; is 0, the currently
//          // installed default allocator is used.
//
//      ~my_MessageFactory();
//          // Destroy this factory and reclaim all messages created by it.
//
//      // MANIPULATORS
//      my_Message *createMessage(const char *data);
//          // Create a message storing the specified &#39;data&#39;.  The behavior is
//          // undefined unless &#39;data&#39; is null-terminated.
//
//      void disposeAllMessages();
//          // Dispose of all created messages.
//
//      void disposeMessage(my_Message *message);
//          // Dispose of the specified &#39;message&#39;.  The behavior is undefined
//          // unless &#39;message&#39; was created by this factory.
//  };
//..
// The use of a multipool and the &#39;release&#39; method enables the
// &#39;disposeAllMessages&#39; method to quickly deallocate all memory blocks used to
// create messages:
//..
//  // MANIPULATORS
//  inline
//  void my_MessageFactory::disposeAllMessages()
//  {
//      d_multipool.release();
//  }
//..
// The multipool can also reuse deallocated memory.  Once a message is
// destroyed by the &#39;disposeMessage&#39; method, memory allocated for that message
// is reclaimed by the multipool and can be used to create the next message
// having the same size:
//..
//  inline
//  void my_MessageFactory::disposeMessage(my_Message *message)
//  {
//      d_multipool.deleteObject(message);
//  }
//..
// A multipool optimizes the allocation of memory by using
// dynamically-allocated buffers (also known as chunks) to supply memory.  As
// each chunk can satisfy multiple memory block requests before requiring
// additional dynamic memory allocation, the number of dynamic allocation
// requests needed is greatly reduced.
//
// For the number of pools managed by the multipool, we chose to use the
// implementation-defined default value instead of calculating and specifying a
// value.  Note that if users want to specify the number of pools, the value
// can be calculated as the smallest &#39;N&#39; such that the following relationship
// holds:
//..
//  N &gt; log2(sizeof(Object Type)) - 2
//..
// Continuing on with the usage example:
//..
//  // CREATORS
//  my_MessageFactory::my_MessageFactory(bslma::Allocator *basicAllocator)
//  : d_multipool(basicAllocator)
//  {
//  }
//..
// Note that in the destructor, all outstanding messages are reclaimed
// automatically when &#39;d_multipool&#39; is destroyed:
//..
//  my_MessageFactory::~my_MessageFactory()
//  {
//  }
//..
// A &#39;bdlma::ConcurrentMultipool&#39; is ideal for allocating the different sized
// messages since repeated deallocations might be necessary (which renders a
// &#39;bcema::SequentialPool&#39; unsuitable) and the sizes of these types are all
// different:
//..
//  // MANIPULATORS
//  my_Message *my_MessageFactory::createMessage(const char *data)
//  {
//      enum { k_SMALL = 8, k_MEDIUM = 16, k_LARGE = 32 };
//
//      const int length = static_cast&lt;int&gt;(bsl::strlen(data));
//
//      if (length &lt; k_SMALL) {
//          return new(d_multipool.allocate(sizeof(my_SmallMessage)))
//                                    my_SmallMessage(data, length);  // RETURN
//      }
//
//      if (length &lt; k_MEDIUM) {
//          return new(d_multipool.allocate(sizeof(my_MediumMessage)))
//                                   my_MediumMessage(data, length);  // RETURN
//      }
//
//      if (length &lt; k_LARGE) {
//          return new(d_multipool.allocate(sizeof(my_LargeMessage)))
//                                    my_LargeMessage(data, length);  // RETURN
//      }
//
//      char *buffer = (char *)d_multipool.allocate(length + 1);
//      bsl::memcpy(buffer, data, length + 1);
//
//      return new(d_multipool.allocate(sizeof(my_GenericMessage)))
//                                                   my_GenericMessage(buffer);
//  }
//..
//
///Example 2: Implementing an Allocator Using &#39;bdlma::ConcurrentMultipool&#39;
///- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
// &#39;bslma::Allocator&#39; is used throughout the interfaces of BDE components.
// Suppose we would like to create a multipool allocator,
// &#39;my_MultipoolAllocator&#39;, that allocates memory from multiple
// &#39;bdlma::ConcurrentPool&#39; objects in a similar fashion to
// &#39;bdlma::ConcurrentMultipool&#39;.  This class can be used directly to implement
// such an allocator.
//
// Note that the documentation for this class is simplified for this usage
// example.  Please see &#39;bdlmca_multipoolallocator&#39; for full documentation of a
// similar class.
//..
//  class my_MultipoolAllocator : public bslma::Allocator{
//      // This class implements the &#39;bslma::Allocator&#39; protocol to provide an
//      // allocator that manages a set of memory pools, each dispensing memory
//      // blocks of a unique size, with each successive pool&#39;s block size
//      // being twice that of the previous one.
//
//      // DATA
//      bdlma::ConcurrentMultipool d_multiPool;  // memory manager for
//                                               // allocated memory blocks
//
//    public:
//      // CREATORS
//      my_MultipoolAllocator(bslma::Allocator *basicAllocator = 0);
//          // Create a multipool allocator.  Optionally specify a
//          // &#39;basicAllocator&#39; used to supply memory.  If &#39;basicAllocator&#39; is
//          // 0, the currently installed default allocator is used.
//
//      // ...
//
//      virtual ~my_MultipoolAllocator();
//          // Destroy this multipool allocator.  All memory allocated from
//          // this memory pool is released.
//
//      // MANIPULATORS
//      virtual void *allocate(int size);
//          // Return the address of a contiguous block of maximally-aligned
//          // memory of (at least) the specified &#39;size&#39; (in bytes).  The
//          // behavior is undefined unless &#39;1 &lt;= size&#39;.
//
//      virtual void deallocate(void *address);
//          // Relinquish the memory block at the specified &#39;address&#39; back to
//          // this multipool allocator for reuse.  The behavior is undefined
//          // unless &#39;address&#39; is non-zero, was allocated by this multipool
//          // allocator, and has not already been deallocated.
//  };
//
//  // CREATORS
//  inline
//  my_MultipoolAllocator::my_MultipoolAllocator(
//                                            bslma::Allocator *basicAllocator)
//  : d_multiPool(basicAllocator)
//  {
//  }
//
//  my_MultipoolAllocator::~my_MultipoolAllocator()
//  {
//  }
//
//  // MANIPULATORS
//  inline
//  void *my_MultipoolAllocator::allocate(int size)
//  {
//      return d_multiPool.allocate(size);
//  }
//
//  inline
//  void my_MultipoolAllocator::deallocate(void *address)
//  {
//      d_multiPool.deallocate(address);
//  }
//..

#ifndef INCLUDED_BDLSCM_VERSION
#include &lt;bdlscm_version.h&gt;
#endif

#ifndef INCLUDED_BDLMA_CONCURRENTALLOCATORADAPTER
#include &lt;bdlma_concurrentallocatoradapter.h&gt;
#endif

#ifndef INCLUDED_BDLMA_BLOCKLIST
#include &lt;bdlma_blocklist.h&gt;
#endif

#ifndef INCLUDED_BSLMA_ALLOCATOR
#include &lt;bslma_allocator.h&gt;
#endif

#ifndef INCLUDED_BSLMA_DELETERHELPER
#include &lt;bslma_deleterhelper.h&gt;
#endif

#ifndef INCLUDED_BSLMT_MUTEX
#include &lt;bslmt_mutex.h&gt;
#endif

#ifndef INCLUDED_BSLS_ALIGNMENTUTIL
#include &lt;bsls_alignmentutil.h&gt;
#endif

#ifndef INCLUDED_BSLS_BLOCKGROWTH
#include &lt;bsls_blockgrowth.h&gt;
#endif

namespace BloombergLP {
namespace bdlma {

class ConcurrentPool;

                        // =========================
                        // class ConcurrentMultipool
                        // =========================

class ConcurrentMultipool {
    // This class implements a memory manager that maintains a configurable
    // number of &#39;bdlma::Pool&#39; objects, each dispensing memory blocks of a
    // unique size.  The &#39;Pool&#39; objects are placed in an array, with each
    // successive pool managing memory blocks of size twice that of the
    // previous pool.  Each multipool allocation (deallocation) request
    // allocates memory from (returns memory to) the internal pool having the
    // smallest block size not less than the requested size, or, if no pool
    // manages memory blocks of sufficient sized, from a separately managed
    // list of memory blocks.  Both the &#39;release&#39; method and the destructor of
    // a &#39;bdema::Multipool&#39; release all memory currently allocated via the
    // object.

    // PRIVATE TYPES
    struct Header {
        // This &#39;struct&#39; provides header information for each allocated memory
        // block.  The header stores the index to the pool used for the memory
        // allocation.

        union {
            int                    d_poolIdx;  // pool used for this memory
                                               // block

            bsls::AlignmentUtil::MaxAlignedType
                                   d_dummy;    // force maximum alignment
        } d_header;
    };

    // DATA
    ConcurrentPool      *d_pools_p;       // array of memory pools, each
                                          // dispensing
                                      // fixed-size memory blocks

    int              d_numPools;      // number of memory pools

    int              d_maxBlockSize;  // largest memory block size; dispensed
                                      // by the &#39;d_numPools - 1&#39;th pool; always
                                      // a power of 2

    bdlma::BlockList  d_blockList;     // memory manager for &quot;large&quot; memory
                                      // blocks.

    bslmt::Mutex      d_mutex;         // synchronize data access

    ConcurrentAllocatorAdapter
                     d_allocAdapter;  // thread-safe adapter

  private:
    // NOT IMPLEMENTED
    ConcurrentMultipool(const ConcurrentMultipool&amp;);
    ConcurrentMultipool&amp; operator=(const ConcurrentMultipool&amp;);

   private:
    // PRIVATE MANIPULATORS
    void initialize(bsls::BlockGrowth::Strategy growthStrategy,
                    int                         maxBlocksPerChunk);
    void initialize(const bsls::BlockGrowth::Strategy *growthStrategyArray,
                    int                                maxBlocksPerChunk);
    void initialize(bsls::BlockGrowth::Strategy  growthStrategy,
                    const int                   *maxBlocksPerChunkArray);
    void initialize(const bsls::BlockGrowth::Strategy *growthStrategyArray,
                    const int                         *maxBlocksPerChunkArray);
        // Initialize this multipool with the specified &#39;growthStrategy[Array]&#39;
        // and &#39;maxBlocksPerChunk[Array]&#39;.  If an array is used, each
        // individual &#39;bdlma::Pool&#39; maintained by this multipool is initialized
        // with the corresponding growth strategy or max blocks per chunk entry
        // within the array.

    // PRIVATE ACCESSORS
    int findPool(int size) const;
        // Return the index of the memory pool in this multipool for an
        // allocation request of the specified &#39;size&#39; (in bytes).  Note that
        // the index of the memory pool managing memory blocks having the
        // minimum block size is 0.

  public:
    // CREATORS
    ConcurrentMultipool(bslma::Allocator *basicAllocator = 0);
    ConcurrentMultipool(int numPools, bslma::Allocator *basicAllocator = 0);
    ConcurrentMultipool(bsls::BlockGrowth::Strategy  growthStrategy,
                        bslma::Allocator            *basicAllocator = 0);
    ConcurrentMultipool(int                          numPools,
                        bsls::BlockGrowth::Strategy  growthStrategy,
                        bslma::Allocator            *basicAllocator = 0);
    ConcurrentMultipool(int                          numPools,
                        bsls::BlockGrowth::Strategy  growthStrategy,
                        int                          maxBlocksPerChunk,
                        bslma::Allocator            *basicAllocator = 0);
        // Create a multipool memory manager.  Optionally specify &#39;numPools&#39;,
        // indicating the number of internally created &#39;Pool&#39; objects; the
        // block size of the first pool is 8 bytes, with the block size of each
        // additional pool successively doubling.  If &#39;numPools&#39; is not
        // specified, an implementation-defined number of pools &#39;N&#39; -- covering
        // memory blocks ranging in size from &#39;2^3 = 8&#39; to &#39;2^(N+2)&#39; -- are
        // created.  Optionally specify a &#39;growthStrategy&#39; indicating whether
        // the number of blocks allocated at once for every internally created
        // &#39;Pool&#39; should be either fixed or grow geometrically, starting with
        // 1.  If &#39;growthStrategy&#39; is not specified, the allocation strategy
        // for each internally created &#39;Pool&#39; object is geometric, starting
        // from 1.  If &#39;numPools&#39; is specified, optionally specify a
        // &#39;maxBlocksPerChunk&#39;, indicating the maximum number of blocks to be
        // allocated at once when a pool must be replenished.  If
        // &#39;maxBlocksPerChunk&#39; is not specified, an implementation-defined
        // value is used.  Optionally specify a &#39;basicAllocator&#39; used to supply
        // memory.  If &#39;basicAllocator&#39; is 0, the currently installed default
        // allocator is used.  Memory allocation (and deallocation) requests
        // will be satisfied using the internally maintained pool managing
        // memory blocks of the smallest size not less than the requested size,
        // or directly from the underlying allocator (supplied at
        // construction), if no internally pool managing memory block of
        // sufficient size exists.  The behavior is undefined unless
        // &#39;1 &lt;= numPools&#39; and &#39;1 &lt;= maxBlocksPerChunk&#39;.  Note that, on
        // platforms where &#39;8 &lt; bsls::AlignmentUtil::BSLS_MAX_ALIGNMENT&#39;,
        // excess memory may be allocated for pools managing smaller blocks.
        // Also note that &#39;maxBlocksPerChunk&#39; need not be an integral power of
        // 2; if geometric growth would exceed the maximum value, the chunk
        // size is capped at that value).

    ConcurrentMultipool(int                                numPools,
                        const bsls::BlockGrowth::Strategy *growthStrategyArray,
                        bslma::Allocator                  *basicAllocator = 0);
    ConcurrentMultipool(int                                numPools,
                        const bsls::BlockGrowth::Strategy *growthStrategyArray,
                        int                                maxBlocksPerChunk,
                        bslma::Allocator                  *basicAllocator = 0);
    ConcurrentMultipool(int                          numPools,
                        bsls::BlockGrowth::Strategy  growthStrategy,
                        const int                   *maxBlocksPerChunkArray,
                        bslma::Allocator            *basicAllocator = 0);
    ConcurrentMultipool(
                     int                                numPools,
                     const bsls::BlockGrowth::Strategy *growthStrategyArray,
                     const int                         *maxBlocksPerChunkArray,
                     bslma::Allocator                  *basicAllocator = 0);
        // Create a multipool memory manager having the specified &#39;numPools&#39;,
        // indicating the number of internally created &#39;Pool&#39; objects; the
        // block size of the first pool is 8 bytes, with the block size of each
        // additional pool successively doubling.  Optionally specify a
        // &#39;growthStrategy&#39; indicating whether the number of blocks allocated
        // at once for every internally created &#39;Pool&#39; should be either fixed
        // or grow geometrically, starting with 1.  If &#39;growthStrategy&#39; is not
        // specified, optionally specify &#39;growthStrategyArray&#39;, indicating the
        // strategies for each individual &#39;Pool&#39; created by this object.  If
        // neither &#39;growthStrategy&#39; nor &#39;growthStrategyArray&#39; are specified,
        // the allocation strategy for each internally created &#39;Pool&#39; object
        // will grow geometrically, starting from 1.  Optionally specify a
        // &#39;maxBlocksPerChunk&#39;, indicating the maximum number of blocks to be
        // allocated at once when a pool must be replenished.  If
        // &#39;maxBlocksPerChunk&#39; is not specified, optionally specify
        // &#39;maxBlocksPerChunkArray&#39;, indicating the maximum number of blocks to
        // allocate at once for each individually created &#39;Pool&#39; object.  If
        // neither &#39;maxBlocksPerChunk&#39; nor &#39;maxBlocksPerChunkArray&#39; are
        // specified, an implementation-defined value is used.  Optionally
        // specify a &#39;basicAllocator&#39; used to supply memory.  If
        // &#39;basicAllocator&#39; is 0, the currently installed default allocator is
        // used.  Memory allocation (and deallocation) requests will be
        // satisfied using the internally maintained pool managing memory
        // blocks of the smallest size not less than the requested size, or
        // directly from the underlying allocator (supplied at construction),
        // if no internally pool managing memory block of sufficient size
        // exists.  The behavior is undefined unless &#39;1 &lt;= numPools&#39;,
        // &#39;growthStrategyArray&#39; has at least &#39;numPools&#39; strategies,
        // &#39;1 &lt;= maxBlocksPerChunk&#39; and &#39;maxBlocksPerChunkArray&#39; have at least
        // &#39;numPools&#39; positive values.  Note that, on platforms where
        // &#39;8 &lt; bsls::AlignmentUtil::BSLS_MAX_ALIGNMENT&#39;, excess memory may be
        // allocated for pools managing smaller blocks.  Also note that the
        // maximum need not be an integral power of 2; if geometric growth
        // would exceed a maximum value, the chunk size is capped at that
        // value).

    ~ConcurrentMultipool();
        // Destroy this multipool.  All memory allocated from this memory pool
        // is released.

    // MANIPULATORS
    void *allocate(int size);
        // Return the address of a contiguous block of maximally-aligned memory
        // of (at least) the specified &#39;size&#39; (in bytes).  If
        // &#39;size &gt; maxPooledBlockSize()&#39;, the memory allocation is managed
        // directly by the underlying allocator, and will not be pooled, but
        // will be deallocated when the &#39;release&#39; method is called, or when
        // this object is destroyed.  The behavior is undefined unless
        // &#39;1 &lt;= size&#39;.

    void deallocate(void *address);
        // Relinquish the memory block at the specified &#39;address&#39; back to this
        // multipool object for reuse.  The behavior is undefined unless
        // &#39;address&#39; is non-zero, was allocated by this multipool object, and
        // has not already been deallocated.

    template &lt;class TYPE&gt;
    void deleteObject(const TYPE *object);
        // Destroy the specified &#39;object&#39; based on its dynamic type and then
        // use this multipool object to deallocate its memory footprint.  This
        // method has no effect if &#39;object&#39; is 0.  The behavior is undefined
        // unless &#39;object&#39;, when cast appropriately to &#39;void *&#39;, was allocated
        // using this multipool object and has not already been deallocated.
        // Note that &#39;dynamic_cast&lt;void *&gt;(object)&#39; is applied if &#39;TYPE&#39; is
        // polymorphic, and &#39;static_cast&lt;void *&gt;(object)&#39; is applied otherwise.

    template &lt;class TYPE&gt;
    void deleteObjectRaw(const TYPE *object);
        // Destroy the specified &#39;object&#39; and then use this multipool to
        // deallocate its memory footprint.  This method has no effect if
        // &#39;object&#39; is 0.  The behavior is undefined unless &#39;object&#39; is !not! a
        // secondary base class pointer (i.e., the address is (numerically) the
        // same as when it was originally dispensed by this multipool), was
        // allocated using this multipool, and has not already been
        // deallocated.

    void release();
        // Relinquish all memory currently allocated via this multipool object.

    void reserveCapacity(int size, int numBlocks);
        // Reserve memory from this multipool to satisfy memory requests for at
        // least the specified &#39;numBlocks&#39; having the specified &#39;size&#39; (in
        // bytes) before the pool replenishes.  The behavior is undefined
        // unless &#39;1 &lt;= size &lt;= maxPooledBlockSize()&#39;, and &#39;0 &lt;= numBlocks&#39;.

    // ACCESSORS
    int numPools() const;
        // Return the number of pools managed by this multipool object.

    int maxPooledBlockSize() const;
        // Return the maximum size of memory blocks that are pooled by this
        // multipool object.  Note that the maximum value is defined as:
        //..
        //  2 ^ (numPools + 2)
        //..
        // where &#39;numPools&#39; is either specified at construction, or an
        // implementation-defined value.

};

// ============================================================================
//                             INLINE DEFINITIONS
// ============================================================================

                        // -------------------------
                        // class ConcurrentMultipool
                        // -------------------------

// MANIPULATORS
template &lt;class TYPE&gt;
inline
void ConcurrentMultipool::deleteObject(const TYPE *object)
{
    bslma::DeleterHelper::deleteObject(object, this);
}

template &lt;class TYPE&gt;
inline
void ConcurrentMultipool::deleteObjectRaw(const TYPE *object)
{
    bslma::DeleterHelper::deleteObjectRaw(object, this);
}

// ACCESSORS
inline
int ConcurrentMultipool::numPools() const
{
    return d_numPools;
}

inline
int ConcurrentMultipool::maxPooledBlockSize() const
{
    return d_maxBlockSize;
}

}  // close package namespace
}  // close enterprise namespace

#endif

// ----------------------------------------------------------------------------
// Copyright 2015 Bloomberg Finance L.P.
//
// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
// ----------------------------- END-OF-FILE ----------------------------------
</pre>
</body>
</html>
